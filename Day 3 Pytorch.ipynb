{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size,output_size):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)    \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(input_size=10, hidden_size=20, output_size=1)\n",
    "example_input = torch.rand(5,10)\n",
    "output = model(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2425],\n",
      "        [0.2261],\n",
      "        [0.2473],\n",
      "        [0.2169],\n",
      "        [0.2384]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer output shape: torch.Size([3, 5])\n",
      "tensor([[ 0.6783, -0.2610, -0.5819,  0.5647, -0.4641],\n",
      "        [ 0.8151, -0.1154,  0.4278,  0.4643, -0.6384],\n",
      "        [-0.7123, -0.4470,  0.6692, -0.1928, -1.3703]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3455, -0.3671,  1.1711, -0.2846, -0.0860,  0.4851,  1.1376, -0.8601,\n",
      "         -0.9491,  0.1943],\n",
      "        [ 0.3307,  1.9745,  0.2175, -0.8470,  0.3009,  1.1676,  0.2371,  0.5839,\n",
      "          0.3851, -2.7478],\n",
      "        [ 1.3860,  0.7465, -0.0153, -0.5678,  2.8607,  0.7468,  0.2005,  0.1278,\n",
      "         -2.5450,  1.0707]])\n"
     ]
    }
   ],
   "source": [
    "#Linear Layer\n",
    "linear = nn.Linear(in_features = 10,out_features = 5)\n",
    "input = torch.randn(3,10)\n",
    "output = linear(input)\n",
    "print(f'Linear layer output shape: { output.shape}')\n",
    "print(output)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=5, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d output shape: torch.Size([2, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Layer\n",
    "conv1d = nn.Conv1d(in_channels = 4,out_channels = 8,kernel_size = 3)\n",
    "input = torch.randn(2, 4, 10)\n",
    "\n",
    "output = conv1d(input)\n",
    "print(f'Conv1d output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1DModel,self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels = 4,\n",
    "        out_channels = 8,kernel_size = 3)\n",
    "\n",
    "        def forward(self,x):\n",
    "            x = self.conv1d(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0664, -0.4032, -0.7565, -0.2504, -0.4786,  0.2583, -0.6346,\n",
      "          -1.1040],\n",
      "         [ 0.3551, -0.1044,  0.4661, -0.1834,  0.2965,  1.9489,  0.6842,\n",
      "           0.3986],\n",
      "         [ 0.0533,  0.3387,  0.2278,  0.2226,  0.1088, -0.4555,  0.4026,\n",
      "           0.1636],\n",
      "         [-0.1535, -0.8992, -0.5656, -0.8650, -0.3265, -0.6561, -1.6292,\n",
      "          -0.6727],\n",
      "         [ 0.0227, -0.2579, -0.3620, -0.3866, -0.8852,  0.2190, -0.0986,\n",
      "           0.5537],\n",
      "         [ 0.3183,  0.7657, -0.1599,  0.6202, -0.9609,  0.3732, -0.6928,\n",
      "          -0.8073],\n",
      "         [-1.0228,  0.0030, -0.4160,  0.3563,  0.0112, -0.0808,  0.0619,\n",
      "          -0.2472],\n",
      "         [ 0.7283, -0.0979,  0.4784, -0.2307,  1.1259, -0.2382, -1.8045,\n",
      "          -0.5070]],\n",
      "\n",
      "        [[-0.3434,  0.9303,  0.5438, -0.1857, -0.1912, -0.4567,  0.5719,\n",
      "           1.1304],\n",
      "         [-1.0103, -0.1623,  0.2143,  0.2757,  0.4245, -0.2410, -1.0461,\n",
      "          -0.2327],\n",
      "         [-0.0556,  0.7745,  0.3468, -0.5527, -0.6332, -0.6312,  0.1542,\n",
      "          -0.3009],\n",
      "         [-0.2911,  0.3379, -0.1325, -0.1671, -0.0740, -0.2812,  0.5826,\n",
      "           0.3678],\n",
      "         [-0.2163, -0.3667,  0.2015,  0.6421,  0.6575, -0.1049, -0.1773,\n",
      "          -0.9329],\n",
      "         [ 0.0107,  0.2464,  0.6298, -0.1164, -0.4243,  0.7248, -0.2405,\n",
      "           0.7934],\n",
      "         [ 0.0259, -0.5007, -1.2575, -1.2695, -1.0140, -0.1605,  0.4111,\n",
      "           0.2571],\n",
      "         [ 0.3591, -0.6330, -0.4609,  0.2143,  0.1222,  0.1782, -0.2444,\n",
      "          -0.5620]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(2,4,10)\n",
    "model = Conv1DModel()\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#MaxPooling\n",
    "pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "input = torch.randn(1,3,8,8)\n",
    "output = pool(input)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#AdaptivePooling\n",
    "adap_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "input = torch.randn(2,13,28,28)\n",
    "out = adap_pool(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n",
      "tensor([[[ 0.1774,  0.5713,  0.2211,  0.4523, -0.2708, -0.1027, -0.0915,\n",
      "          -0.1152, -0.2256,  0.2872,  0.0705, -0.2821, -0.2335, -0.0925,\n",
      "           0.2727, -0.2004,  0.0352,  0.4005, -0.0733, -0.1217],\n",
      "         [ 0.3629, -0.3504,  0.4153, -0.0232, -0.1214,  0.0812, -0.1560,\n",
      "          -0.0479,  0.6162, -0.1182, -0.4909,  0.1877, -0.1906, -0.2123,\n",
      "           0.3481,  0.1309,  0.0488, -0.0844,  0.2475,  0.0508],\n",
      "         [ 0.0057, -0.5791,  0.3520, -0.1079,  0.2332, -0.1891, -0.1559,\n",
      "          -0.1320,  0.2642, -0.2227,  0.1889,  0.2030, -0.3330,  0.2293,\n",
      "           0.3269, -0.1241,  0.1653, -0.4509,  0.2821,  0.1670]],\n",
      "\n",
      "        [[ 0.0984,  0.3015,  0.2510,  0.2133, -0.2737, -0.0459,  0.0452,\n",
      "          -0.0629, -0.2754,  0.1409,  0.1619, -0.1978, -0.0574,  0.0263,\n",
      "           0.1184, -0.1506, -0.0908,  0.2376,  0.0155, -0.0994],\n",
      "         [ 0.1830, -0.4847,  0.3111, -0.0293, -0.1618, -0.0610, -0.1165,\n",
      "          -0.0724,  0.2067, -0.0354, -0.1113,  0.1354, -0.1519, -0.0332,\n",
      "           0.2293,  0.0160, -0.0027, -0.1491,  0.2626,  0.0658],\n",
      "         [-0.0987, -0.4216,  0.3699, -0.1465,  0.0189, -0.1320, -0.0978,\n",
      "          -0.1531,  0.3114, -0.1323,  0.0580,  0.0638, -0.1726,  0.1311,\n",
      "           0.1827, -0.0710,  0.0428, -0.3045,  0.1784,  0.1220]],\n",
      "\n",
      "        [[ 0.0728,  0.1883,  0.1902,  0.1120, -0.2527, -0.0124,  0.0854,\n",
      "          -0.0384, -0.1633,  0.0645,  0.1555, -0.1437,  0.0467,  0.0434,\n",
      "           0.0135, -0.1409, -0.1090,  0.1730,  0.0677, -0.0478],\n",
      "         [ 0.0664, -0.3751,  0.2842, -0.0217, -0.1564, -0.0942, -0.0707,\n",
      "          -0.0515,  0.1084,  0.0082, -0.0085,  0.0637, -0.1050,  0.0149,\n",
      "           0.1054, -0.0328, -0.0245, -0.1291,  0.2104,  0.0742],\n",
      "         [-0.1279, -0.3186,  0.3156, -0.1588, -0.0677, -0.1029, -0.0489,\n",
      "          -0.1195,  0.2032, -0.0878,  0.0554,  0.0336, -0.1201,  0.1147,\n",
      "           0.0462, -0.0520, -0.0085, -0.2264,  0.1178,  0.0773]],\n",
      "\n",
      "        [[ 0.0403,  0.1090,  0.1515,  0.0569, -0.1998, -0.0065,  0.1048,\n",
      "          -0.0145, -0.0706,  0.0196,  0.1565, -0.0785,  0.0770,  0.0535,\n",
      "          -0.0226, -0.1207, -0.0800,  0.1385,  0.1063, -0.0200],\n",
      "         [-0.0084, -0.2885,  0.2702, -0.0371, -0.1447, -0.0947, -0.0350,\n",
      "          -0.0447,  0.0536,  0.0168,  0.0516,  0.0351, -0.0808,  0.0470,\n",
      "           0.0394, -0.0494, -0.0356, -0.1155,  0.1836,  0.0610],\n",
      "         [-0.1240, -0.2340,  0.2635, -0.1546, -0.1170, -0.0630, -0.0167,\n",
      "          -0.1420,  0.0832, -0.0654,  0.0576,  0.0416, -0.0803,  0.0828,\n",
      "          -0.0574, -0.0452, -0.0549, -0.1889,  0.0740,  0.0810]],\n",
      "\n",
      "        [[ 0.0147,  0.0400,  0.1328,  0.0171, -0.1530,  0.0031,  0.1045,\n",
      "          -0.0277, -0.0130, -0.0220,  0.1580, -0.0261,  0.0675,  0.0532,\n",
      "          -0.0516, -0.0922, -0.0736,  0.0776,  0.1138, -0.0043],\n",
      "         [-0.0326, -0.2100,  0.2454, -0.0589, -0.1670, -0.0765,  0.0060,\n",
      "          -0.0453,  0.0227,  0.0142,  0.0631,  0.0075, -0.0629,  0.0768,\n",
      "           0.0106, -0.0402, -0.0469, -0.0912,  0.1607,  0.0480],\n",
      "         [-0.1095, -0.1672,  0.2111, -0.1271, -0.1433, -0.0478,  0.0090,\n",
      "          -0.1211,  0.0256, -0.0364,  0.0525,  0.0507, -0.0360,  0.0771,\n",
      "          -0.0803, -0.0435, -0.0421, -0.1552,  0.1022,  0.0711]]],\n",
      "       grad_fn=<MkldnnRnnLayerBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "lstm = nn.LSTM(input_size = 10,hidden_size = 20,num_layers = 2)\n",
    "inp_seq = torch.randn(5,3,10)\n",
    "\n",
    "ho = torch.randn(2,3,20)\n",
    "\n",
    "co = torch.randn(2,3,20)\n",
    "output, (ho,co) = lstm(inp_seq,(ho,co))\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTModel(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers,output_size):\n",
    "        super(LSTModel).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = input_size,hidden_size = hidden_size,num_layers = num_layers,batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        lstm_out,(hidden_state,cell_state) = self.lstm(x)\n",
    "        out = self.fc(hidden_state[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,input_size)\n\u001b[0;32m      5\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m, in \u001b[0;36mLSTModel.__init__\u001b[1;34m(self, input_size, hidden_size, num_layers, output_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,input_size,hidden_size,num_layers,output_size):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(LSTModel)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLSTM(input_size \u001b[38;5;241m=\u001b[39m input_size,hidden_size \u001b[38;5;241m=\u001b[39m hidden_size,num_layers \u001b[38;5;241m=\u001b[39m num_layers,batch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size,output_size)\n",
      "File \u001b[1;32mc:\\Users\\91995\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1737\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Module):\n\u001b[0;32m   1736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1738\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign module before Module.__init__() call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1739\u001b[0m     remove_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set)\n\u001b[0;32m   1740\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m _global_module_registration_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "\u001b[1;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "input_size = 10\n",
    "model = LSTModel(10,20,2,1)\n",
    "x = torch.randn(3,5,input_size)\n",
    "\n",
    "output = model(x)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
